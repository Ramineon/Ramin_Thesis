{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model 1\n",
    "\n",
    "This is simple CNN Model for training on Rp image's"
   ],
   "id": "a5a1961ba1d27f05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T07:55:18.611991Z",
     "start_time": "2024-12-04T07:55:15.480951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ],
   "id": "c960714e91f8a1f8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## initiation:",
   "id": "f520124c446ce9d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T08:02:28.595572Z",
     "start_time": "2024-12-04T08:02:27.628155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "from Prop.16\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "class TensorDataset(Dataset):  # squeezed for adding one channel tensor\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.files = []\n",
    "        for class_idx, class_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for file_name in os.listdir(class_path):\n",
    "                    file_path = os.path.join(class_path, file_name)\n",
    "                    if file_name.endswith(\".pt\"):\n",
    "                        self.files.append((file_path, class_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.files[idx]\n",
    "        tensor = torch.load(file_path)  # Load the tensor\n",
    "        tensor = tensor.unsqueeze(0)   # Add channel dimension: [1, 160, 160]\n",
    "        return tensor, label\n",
    "\n",
    "\n",
    "# Path to your dataset\n",
    "patheon = r\"F:\\TheLis\\2_Class\"\n",
    "\n",
    "# Load the dataset\n",
    "dataset = TensorDataset(root_dir=patheon)\n",
    "\n",
    "# Define the train/test split ratio\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Randomly split the dataset\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Define DataLoaders for both training and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Verify the DataLoader\n",
    "for tensors, labels in train_loader:\n",
    "    print(\"Batch tensors shape:\", tensors.shape)\n",
    "    print(\"Batch labels:\", labels)\n",
    "    break"
   ],
   "id": "2e6f8722c6ba7096",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8340\\3990497913.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tensor = torch.load(file_path)  # Load the tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch tensors shape: torch.Size([64, 1, 160, 160])\n",
      "Batch labels: tensor([1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model:",
   "id": "c7f6ec2e462c831"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:43:12.064135Z",
     "start_time": "2024-12-03T12:43:11.919145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ImprovedCNNWithTransformer2(nn.Module):\n",
    "    def __init__(self, num_classes=4, num_transformer_layers=4, num_heads=8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional Layers (updated for single-channel input)\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)  # 1 -> 16\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)  # 16 -> 32\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)  # 32 -> 64\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)  # 64 -> 128 (New Layer)\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=2),  # Match dimensions for residual connection\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(16)  # Updated BatchNorm layers\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Transformer Parameters\n",
    "        self.embed_dim = 128  # Keep embedding size to match final convolution output\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((4, 4))  # Fixed-size output for tokenization\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=self.embed_dim, nhead=num_heads, dim_feedforward=512, dropout=0.4, batch_first=True)\n",
    "        self.transformer = TransformerEncoder(encoder_layer, num_layers=num_transformer_layers)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(self.embed_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Block 2\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Block 3\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)               #### i add myself\n",
    "\n",
    "        # Block 4 with Residual\n",
    "        shortcut = self.shortcut(x)  # Downsample shortcut\n",
    "        x = F.relu(self.bn4(self.conv4(x)) + shortcut)\n",
    "\n",
    "        # Global Pooling\n",
    "        x = self.global_pool(x)  # Shape: [batch_size, 128, 4, 4]\n",
    "        batch_size, channels, height, width = x.size()\n",
    "\n",
    "        # Prepare Transformer Input\n",
    "        x = x.view(batch_size, channels, -1).permute(0, 2, 1)  # Shape: [batch, 16, 128]\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer(x)  # Shape: [batch, 16, 128]\n",
    "        x = x.mean(dim=1)  # Aggregate token representations (Shape: [batch, 128])\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = ImprovedCNNWithTransformer2()\n",
    "\n",
    "# eval to Model Work right of not ?\n",
    "input_tensor = torch.randn(64, 1, 160, 160)  # Batch size 8, single channel, 160x160 resolution\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  # Expected: [8, num_classes]"
   ],
   "id": "2a3f6a1920bc3fd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T08:02:38.539947Z",
     "start_time": "2024-12-04T08:02:38.275737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class ImprovedCNNWithTransformer_v2(nn.Module):\n",
    "    def __init__(self, num_classes=2, num_transformer_layers=2, num_heads=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Transformer Parameters\n",
    "        self.embed_dim = 256  # Token embedding size\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((4, 4))  # Pooling for fixed-size input to Transformer\n",
    "\n",
    "        # encoder_layer = TransformerEncoderLayer(d_model=self.embed_dim, nhead=num_heads, dim_feedforward=512, dropout=0.3)\n",
    "        # self.transformer = TransformerEncoder(encoder_layer, num_layers=num_transformer_layers)\n",
    "\n",
    "\n",
    "\n",
    "        # Transformer Encoder Layer with batch_first=True\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=self.embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=512,\n",
    "            dropout=0.3,\n",
    "            batch_first=True  # Ensure batch dimension is first\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(encoder_layer, num_layers=num_transformer_layers)\n",
    "\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(self.embed_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Block 2\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Block 3\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Block 4\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Global Pooling\n",
    "        x = self.global_pool(x)  # Shape: [batch_size, 256, 4, 4]\n",
    "        batch_size, channels, height, width = x.size()\n",
    "\n",
    "        # Prepare Transformer Input\n",
    "        x = x.view(batch_size, channels, -1).permute(0, 2, 1)  # Shape: [batch, 16, 256]\n",
    "        # x = x.view(batch_size, channels, -1).permute(0, 2, 1)  # Shape: [batch_size, seq_len, embed_dim]\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer(x)  # Shape: [batch, 16, 256]\n",
    "        x = x.mean(dim=1)  # Aggregate token representations (Shape: [batch, 256])\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = ImprovedCNNWithTransformer_v2()\n",
    "\n",
    "# eval to Model Work right of not ?\n",
    "input_tensor = torch.randn(64, 1, 160, 160)  # Batch size 8, single channel, 160x160 resolution\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  # Expected: [8, num_classes]"
   ],
   "id": "cc99df893c57cadf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Eval Section:",
   "id": "2963d2435bff65a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T08:05:37.132236Z",
     "start_time": "2024-12-04T08:02:42.554389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "num_epochs = 70  # Assuming a total of 50 epochs\n",
    "model.to(device)\n",
    "\n",
    "# Variable to track the best model\n",
    "best_test_accuracy = 0.0\n",
    "best_model_path = \"best_model.pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Training loop\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate training metrics\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, \"\n",
    "          f\"Accuracy: {epoch_accuracy:.2%}, \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # Start testing after 40th epoch\n",
    "    if epoch >= 19:\n",
    "        model.eval()\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "        # Calculate test accuracy\n",
    "        test_accuracy = correct_predictions / total_samples\n",
    "        print(f\"Test Accuracy after Epoch {epoch+1}: {test_accuracy:.2%}\")\n",
    "\n",
    "        # Save the model if it's the best so far\n",
    "        if test_accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved with accuracy: {best_test_accuracy:.2%}\")\n",
    "\n",
    "# Load the best model for further use\n",
    "print(f\"Training complete. Best model accuracy: {best_test_accuracy:.2%}\")\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ],
   "id": "6de36378989f3da1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8340\\3990497913.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tensor = torch.load(file_path)  # Load the tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/70], Loss: 0.5503, Accuracy: 70.39%, LR: 0.000300\n",
      "Epoch [2/70], Loss: 0.4777, Accuracy: 77.65%, LR: 0.000300\n",
      "Epoch [3/70], Loss: 0.4723, Accuracy: 78.09%, LR: 0.000300\n",
      "Epoch [4/70], Loss: 0.4631, Accuracy: 78.90%, LR: 0.000300\n",
      "Epoch [5/70], Loss: 0.4193, Accuracy: 80.94%, LR: 0.000300\n",
      "Epoch [6/70], Loss: 0.4380, Accuracy: 78.90%, LR: 0.000300\n",
      "Epoch [7/70], Loss: 0.4486, Accuracy: 80.37%, LR: 0.000300\n",
      "Epoch [8/70], Loss: 0.4132, Accuracy: 81.26%, LR: 0.000300\n",
      "Epoch [9/70], Loss: 0.4247, Accuracy: 80.99%, LR: 0.000300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m total_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Training loop\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m     20\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     22\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:697\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    696\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m--> 697\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_profile_name):\n\u001B[0;32m    698\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m             \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\autograd\\profiler.py:738\u001B[0m, in \u001B[0;36mrecord_function.__exit__\u001B[1;34m(self, exc_type, exc_value, traceback)\u001B[0m\n\u001B[0;32m    733\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecord \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39m_record_function_enter_new(\n\u001B[0;32m    734\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\n\u001B[0;32m    735\u001B[0m     )\n\u001B[0;32m    736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m--> 738\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001B[0;32m    739\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_callbacks_on_exit:\n\u001B[0;32m    740\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Accuracy:",
   "id": "cfb28aa49016900f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:01:44.497891Z",
     "start_time": "2024-12-03T13:01:43.718359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Test section\n",
    "\n",
    "Explanation of Metrics\n",
    "Overall Test Accuracy:\n",
    "\n",
    "Direct comparison of predicted vs. actual labels across the entire test set.\n",
    "accuracy_score(all_labels, all_preds) calculates this metric.\n",
    "Per-Class Accuracy:\n",
    "\n",
    "Measures the accuracy of the model for each individual class.\n",
    "Computed using the diagonal values of the confusion matrix (correct predictions per class) divided by the number of samples per class.\n",
    "Classification Report:\n",
    "\n",
    "Includes precision, recall, and F1-score for each class.\n",
    "This provides a detailed understanding of how well the model performs for each class, especially in cases of class imbalance.\n",
    "Confusion Matrix:\n",
    "\n",
    "Shows the number of true positives, false positives, false negatives, and true negatives for each class.\n",
    "Useful for diagnosing specific patterns of misclassification.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays for evaluation\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Overall accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Overall Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Per-class accuracy\n",
    "    class_accuracy = np.diag(confusion_matrix(all_labels, all_preds)) / np.bincount(all_labels)\n",
    "    for i, acc in enumerate(class_accuracy):\n",
    "        print(f\"Class {i} Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=dataset.classes))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Test the model\n",
    "test_accuracy = evaluate_model(model, test_loader, device)"
   ],
   "id": "aa5f73f8f58df35",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8076\\2620370336.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tensor = torch.load(file_path)  # Load the tensor\n",
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Test Accuracy: 0.7780\n",
      "Class 0 Accuracy: 0.8261\n",
      "Class 1 Accuracy: 0.6613\n",
      "Class 2 Accuracy: 0.8480\n",
      "Class 3 Accuracy: 0.7794\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.83      0.74       115\n",
      "           2       0.73      0.66      0.69       124\n",
      "           3       0.88      0.85      0.86       125\n",
      "           4       0.85      0.78      0.82       136\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.78      0.78      0.78       500\n",
      "weighted avg       0.79      0.78      0.78       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 95  15   0   5]\n",
      " [ 35  82   2   5]\n",
      " [  1  10 106   8]\n",
      " [ 11   6  13 106]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2467ddc46dbf9457"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
