{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydrive_path = '/home/ramineon/Proposal/Test_Thesis_Dataset/data'\n",
    "mydrive_path = '/home/ramineon/Proposal/Thesis1/data'\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define the transformations for both training and test data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),       # Resize images to 224x224 for VGG16\n",
    "    transforms.ToTensor(),               # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])  # Normalize for pre-trained models\n",
    "])\n",
    "patheon = mydrive_path\n",
    "# Load the dataset\n",
    "dataset = datasets.ImageFolder(root=patheon, transform=transform)\n",
    "\n",
    "# Define the train/test split ratio\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Randomly split the dataset\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Define DataLoaders for both training and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramineon/ThesisEon/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class ImprovedCNNWithTransformer(nn.Module):\n",
    "    def __init__(self, num_classes=2, num_transformer_layers=4, num_heads=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Transformer Parameters\n",
    "        self.embed_dim = 128  # Token embedding size\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((4, 4))  # Fixed-size output for tokenization\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=self.embed_dim, nhead=num_heads, dim_feedforward=512, dropout=0.4)\n",
    "        self.transformer = TransformerEncoder(encoder_layer, num_layers=num_transformer_layers)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(self.embed_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Block 2\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Block 3 with Residual\n",
    "        shortcut = self.shortcut(x)  # Downsample shortcut\n",
    "        x = F.relu(self.bn3(self.conv3(x)) + shortcut)\n",
    "        \n",
    "        # Global Pooling\n",
    "        x = self.global_pool(x)  # Shape: [batch_size, 128, 4, 4]\n",
    "        batch_size, channels, height, width = x.size()\n",
    "\n",
    "        # Prepare Transformer Input\n",
    "        x = x.view(batch_size, channels, -1).permute(0, 2, 1)  # Shape: [batch, 16, 128]\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        x = self.transformer(x)  # Shape: [batch, 16, 128]\n",
    "        x = x.mean(dim=1)  # Aggregate token representations (Shape: [batch, 128])\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = ImprovedCNNWithTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.0502, Accuracy: 98.15%, LR: 0.000300\n",
      "Test Accuracy: 89.74%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Updated optimizer with weight decay\n",
    "# optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "num_epochs = 1  # Adjust as needed\n",
    "model.to(device)  # Ensure the model is moved to the device\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Training loop\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "\n",
    "        # Forward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Print detailed epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, \"\n",
    "          f\"Accuracy: {epoch_accuracy:.2%}, \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "# Print test accuracy\n",
    "test_accuracy = correct_predictions / total_samples\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Test Accuracy: 0.9167\n",
      "Class 0 Accuracy: 0.9211\n",
      "Class 1 Accuracy: 0.9125\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.92      0.92        76\n",
      "           2       0.92      0.91      0.92        80\n",
      "\n",
      "    accuracy                           0.92       156\n",
      "   macro avg       0.92      0.92      0.92       156\n",
      "weighted avg       0.92      0.92      0.92       156\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[70  6]\n",
      " [ 7 73]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test section\n",
    "\n",
    "Explanation of Metrics\n",
    "Overall Test Accuracy:\n",
    "\n",
    "Direct comparison of predicted vs. actual labels across the entire test set.\n",
    "accuracy_score(all_labels, all_preds) calculates this metric.\n",
    "Per-Class Accuracy:\n",
    "\n",
    "Measures the accuracy of the model for each individual class.\n",
    "Computed using the diagonal values of the confusion matrix (correct predictions per class) divided by the number of samples per class.\n",
    "Classification Report:\n",
    "\n",
    "Includes precision, recall, and F1-score for each class.\n",
    "This provides a detailed understanding of how well the model performs for each class, especially in cases of class imbalance.\n",
    "Confusion Matrix:\n",
    "\n",
    "Shows the number of true positives, false positives, false negatives, and true negatives for each class.\n",
    "Useful for diagnosing specific patterns of misclassification.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays for evaluation\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Overall accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Overall Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Per-class accuracy\n",
    "    class_accuracy = np.diag(confusion_matrix(all_labels, all_preds)) / np.bincount(all_labels)\n",
    "    for i, acc in enumerate(class_accuracy):\n",
    "        print(f\"Class {i} Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=dataset.classes))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Test the model\n",
    "test_accuracy = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_complete.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Loading a Saved Model\n",
    "# Load Only Model Parameters:\n",
    "# First, recreate the model architecture, then load the saved weights.\n",
    "# python\n",
    "# Copy code\n",
    "# Recreate the model architecture\n",
    "model = ImprovedCNNWithTransformer(num_classes=2)  # Ensure the architecture matches\n",
    "\n",
    "# Load the weights\n",
    "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "# Load the Entire Model:\n",
    "# Directly load the saved model.\n",
    "# python\n",
    "# Copy code\n",
    "model = torch.load(\"model_complete.pth\")\n",
    "model.eval()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If you save the model on one device (e.g., GPU) and load it on another (e.g., CPU), use map_location when loading:\n",
    "\"\"\"\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss\n",
    "}, \"checkpoint.pth\")\n",
    "\n",
    "\"\"\"\n",
    "Saving Optimizer State (Optional):\n",
    "If you want to resume training later, save the optimizer's state too:\n",
    "\"\"\"\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss\n",
    "}, \"checkpoint.pth\")\n",
    "\n",
    "\"\"\"\n",
    "To load the checkpoint:\n",
    "\"\"\"\n",
    "checkpoint = torch.load(\"checkpoint.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ramineon/Proposal/Thesis ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Prints the current working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
